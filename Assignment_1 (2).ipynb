{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U6nmdGzDLHo"
      },
      "outputs": [],
      "source": [
        "#Name - Shweta\n",
        "#Enrollment ID: 0012"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Web Scrapping"
      ],
      "metadata": {
        "id": "CNr8DIJ0D6qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKQvNatOAiqf",
        "outputId": "1359c282-2efc-4d56-ef2e-893de64fbf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the data from given link using webscrapping\n",
        "url = 'https://en.wikipedia.org/wiki/Mount_Everest'\n",
        "page = urlopen(url)\n",
        "html = page.read().decode(\"utf-8\")\n",
        "#count total number of Mount\n",
        "html.count('Mount')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV_GOd5FD1sg",
        "outputId": "fc906ef9-6f38-4d67-e675-301a60422e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1288"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "zix5ei-BDdBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting plain text\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "mount = soup.get_text()\n",
        "#change the plain text to uppercase\n",
        "mount_upper = mount.upper()\n",
        "##add the plain text content in a file name mount.txt\n",
        "f = open('mount.txt', 'w', encoding=\"utf-8\")\n",
        "f.write(mount_upper)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "0sHizpk68tij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##print the title of this page\n",
        "soup.title.string"
      ],
      "metadata": {
        "id": "XAIJsc5HBF4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e400b1c8-9675-4d00-fa14-e04ea998f419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mount Everest - Wikipedia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Read the following Pdf file"
      ],
      "metadata": {
        "id": "1j8TaRasb1jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##installed library for pdf and doc.file\n",
        "!pip install pypdf Spire.Doc -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-yceHbjpG1U",
        "outputId": "13559d69-e055-4663-8821-904fd13f5a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: Spire.Doc in /usr/local/lib/python3.10/dist-packages (12.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Requirement already satisfied: plum-dispatch==1.7.4 in /usr/local/lib/python3.10/dist-packages (from Spire.Doc) (1.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read the given file\n",
        "from pypdf import PdfReader\n",
        "reader = PdfReader('introduction-to-natural-language-processing.pdf')"
      ],
      "metadata": {
        "id": "u4HPfu75otEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print Page 12 of the pdf\n",
        "page_12 = reader.pages[11]\n",
        "page_12 = page_12.extract_text()\n",
        "print(page_12)"
      ],
      "metadata": {
        "id": "VRTzDoYKpBwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c2b0da-d925-4430-b046-6619df1b806e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CO3354 Introduction to natural language processing\n",
            "1.3 Learning outcomes\n",
            "On successful completion of this course, including recommended readings, exercises\n",
            "and activities, you should be able to:\n",
            "1. utilise and explain the function of software tools such as corpus readers,\n",
            "stemmers, taggers and parsers\n",
            "2. explain the difference between regular and context-free grammars and deﬁne\n",
            "formal grammars for fragments of a natural language\n",
            "3. critically appraise existing Natural Language Processing (NLP) applications such\n",
            "as chatbots and translation systems\n",
            "4. describe some applications of statistical techniques to natural language analysis,\n",
            "such as classiﬁcation and probabilistic parsing.\n",
            "Each main chapter contains a list of learning outcomes speciﬁc to that chapter at the\n",
            "beginning, as well as a summary at the end of the chapter.\n",
            "1.4 Reading list and other learning resources\n",
            "This is a list of textbooks and other resources which will be useful for all or most\n",
            "parts of the course. Additional readings will be given at the start of each chapter. See\n",
            "the bibliography for a full list of books and articles referred to, including all ISBNs.\n",
            "In some cases several different books will be listed: you are not expected to read all\n",
            "of them, rather the intention is to give you some alternatives in case particular texts\n",
            "are hard to obtain.\n",
            "Essential reading\n",
            "Bird, Klein, and Loper (2009): Natural Language Processing with Python . The full\n",
            "text including diagrams is freely available online at http://nltk.org/book (last\n",
            "visited 13th April 2013). The main textbook for this course, Natural Language\n",
            "Processing with Python is the outcome of a project extending over several years\n",
            "to develop the Natural Language Toolkit (NLTK), which is a set of tools and\n",
            "resources for teaching computational linguistics. The NLTK comprises a suite of\n",
            "software modules written in Python and a collection of corpora and other\n",
            "resources. See section 1.5 below for advice on installing the NLTK and other\n",
            "software packages.\n",
            "In the course of working through this text you will gain some experience and\n",
            "familiarity with the Python language, though you will not be expected to\n",
            "produce substantial original code as part of the learning outcomes of the course.\n",
            "Recommended reading\n",
            "Pinker (2007). The Language Instinct . This book is aimed at non-specialists and\n",
            "deals with many psychological and cultural aspects of language. Chapter 4 is\n",
            "particularly relevant to this course as it provides a clear and accessible\n",
            "presentation of two standard techniques for modelling linguistic structure:\n",
            "ﬁnite-state machines and context-free grammars (though Pinker does not in fact\n",
            "use these terms, as we will see in Chapter 2 of the subject guide).\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print page 13 of the pdf\n",
        "page_13 = reader.pages[12]\n",
        "page_13 = page_13.extract_text()\n",
        "print(page_13)"
      ],
      "metadata": {
        "id": "rj7V1A-xprz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2825cda9-3450-4db7-d9a0-e4acb667356f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading list and other learning resources\n",
            "Jurafsky and Martin (2009): Speech and Language Processing , second edition.\n",
            "Currently the deﬁnitive introductory textbook in this ﬁeld, covering the major\n",
            "topics in a way which combines theoretical issues with presentations of key\n",
            "technologies, formalisms and mathematical techniques. Much of this book goes\n",
            "beyond what you will need to pass this course, but it is always worth turning to\n",
            "if you’re looking for a more in-depth discussion of any particular topics.\n",
            "Perkins (2010): Python Text Processing with NLTK 2.0 Cookbook . This book will be\n",
            "suitable for students who want to get more practice in applying Python\n",
            "programming to natural language processing. Perkins explains several\n",
            "techniques and algorithms in more technical detail than Bird et al. (2009) and\n",
            "provides a variety of worked examples and code snippets.\n",
            "Segaran (2007) Programming Collective Intelligence . This highly readable and\n",
            "informative text includes tutorial material on machine learning techniques using\n",
            "the Python language.\n",
            "Additional reading\n",
            "Russell and Norvig (2010) Artiﬁcial Intelligence: a modern approach , third edition.\n",
            "This book is currently regarded as the deﬁnitive textbook in Artiﬁcial\n",
            "Intelligence, and includes useful material on natural language processing as well\n",
            "as on machine learning, which has many applications in NLP.\n",
            "Mitkov (2003) The Oxford Handbook of Computational Linguistics . Edited by Ruslan\n",
            "Mitkov. A collection of short articles on major topics in the ﬁeld, contributed by\n",
            "acknowledged experts in their respective disciplines.\n",
            "Partee et al. (1990) Mathematical Methods in Linguistics . A classic text, whose\n",
            "contents indicate how much the ﬁeld has changed since its publication. A book\n",
            "with such a title nowadays would be expected to include substantial coverage of\n",
            "statistics, probability and information theory, but this text is devoted exclusively\n",
            "to discrete mathematics including set theory, formal logic, algebra and automata.\n",
            "These topics are particularly applicable to the content of Chapters 2 and 6.\n",
            "Websites\n",
            "Introductory/Reference The Internet Grammar of English is a clear and informative\n",
            "introductory guide to English grammar which also serves as a tutorial in\n",
            "grammatical terminology and concepts. The site is hosted by the Survey of\n",
            "English Usage at University College London\n",
            "(http://www.ucl.ac.uk/internet-grammar/home.htm, last visited 27th May\n",
            "2013).\n",
            "Hands-on corpus analysis\n",
            "BNCWeb is a web-based interface to the British National Corpus hosted at Lancaster\n",
            "University which supports a variety of online queries for corpus analysis\n",
            "(http://bncweb.info/; last visited 27th May 2013).\n",
            "The Bank of English forms part of the Collins Corpus, developed by Collins\n",
            "Dictionaries and the University of Birmingham. Used as a basis for Collins\n",
            "Advanced Learner’s Dictionary, grammars and various tutorial materials for\n",
            "learners of English. Limited online access at\n",
            "http://www.collinslanguage.com/wordbanks; (last visited 27th May 2013).\n",
            "Journals and conferences\n",
            "Computational Linguistics is the leading journal in this ﬁeld and is freely available at\n",
            "http://www.mitpressjournals.org/loi/coli (last visited 27th May 2013).\n",
            "Conference Proceedings are often freely downloadable and many of these are\n",
            "hosted by the ACL Anthology at http://aclweb.org/anthology-new/ (last visited\n",
            "27th May 2013).\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the reason behind following two codes is because\n",
        "#of confusion in understanding the question:-\n",
        "\n",
        "#to save whole content in file nlp.txt\n",
        "nlp = ''\n",
        "for page in reader.pages:\n",
        "    nlp += page.extract_text()\n",
        "f = open('nlp.txt', 'w', encoding=\"utf-8\")\n",
        "f.write(nlp)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "1Ox2kSMa3tsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to save content of page 12 and 13 in file nlp.txt\n",
        "nlp = page_12 + \" \\n\" + page_13\n",
        "f = open('nlp.txt', 'w', encoding=\"utf-8\")\n",
        "f.write(nlp)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "eNuHDP923x42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Read the following doc file"
      ],
      "metadata": {
        "id": "efcXG2eidy1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "TRpSyY6hqexw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read the doc file\n",
        "from spire.doc import Document\n",
        "document = Document()\n",
        "document.LoadFromFile('Machine-Learning-and-Natural-Language-Processing.docx')\n",
        "document_text = document.GetText()"
      ],
      "metadata": {
        "id": "tBlD506wXwCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to print first 3 paragraph (given document contains only 3 paragraphs not 5)\n",
        "#it will give error if mentioned 5\n",
        "section = document.Sections[0]\n",
        "for i in range(0,3):\n",
        "  paragraph = section.Paragraphs[i]\n",
        "  print(paragraph.Text)\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWgZTn9vg2WT",
        "outputId": "3dff96b2-a37c-4e8b-ece8-4db04c036df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Warning: The document was created with Spire.Doc for Python.\n",
            "Machine Learning and Natural Language Processing\u000bPercy Liang\n",
            "Abstract: Machine learning plays a vital role in modern natural language processing (NLP), enabling the construction of robust machine translation, speech recognition, and question answering systems.  An underdeveloped but critical component required for further advancing the state-of-the-art is semantics, a topic that has been receiving increasing attention.  In this talk, I will first give an overview of various semantic models and the linguistic phenomena they seek to capture.  Then, I will walk through a model for question answering that learns logical forms in an unsupervised way.  Learning such a model requires dealing with both combinatorial explosions and non-convexities, heavily stressing existing machine learning techniques.  I will conclude by highlighting how these challenges point to exciting opportunities for developing new learning algorithms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of \"The' present in given document\n",
        "document_text.count(\"the\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGbgTeI0h4sQ",
        "outputId": "a91e937b-419f-49dc-9b53-4f6ef3feba7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    }
  ]
}